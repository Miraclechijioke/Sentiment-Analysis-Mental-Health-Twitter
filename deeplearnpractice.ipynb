{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -r deeplearnreq.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[31mERROR: Invalid requirement: '{' (from line 1 of deeplearnreq.txt)\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting tensorflow\n  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nCollecting absl-py>=1.0.0 (from tensorflow)\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting astunparse>=1.6.0 (from tensorflow)\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting flatbuffers>=24.3.25 (from tensorflow)\n  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\nCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting google-pasta>=0.1.1 (from tensorflow)\n  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\nCollecting h5py>=3.10.0 (from tensorflow)\n  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting libclang>=13.0.0 (from tensorflow)\n  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\nCollecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting opt-einsum>=2.3.2 (from tensorflow)\n  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (24.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (4.25.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (69.5.1)\nRequirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nCollecting termcolor>=1.1.0 (from tensorflow)\n  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: typing-extensions>=3.6.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (1.64.1)\nCollecting tensorboard<2.18,>=2.17 (from tensorflow)\n  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting keras>=3.2.0 (from tensorflow)\n  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow) (1.23.5)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nCollecting rich (from keras>=3.2.0->tensorflow)\n  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\nCollecting namex (from keras>=3.2.0->tensorflow)\n  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\nCollecting optree (from keras>=3.2.0->tensorflow)\n  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\nRequirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: werkzeug>=1.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\nCollecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow)\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\nCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow)\n  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\nDownloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\nDownloading gast-0.6.0-py3-none-any.whl (21 kB)\nDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\nDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\nDownloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rich-13.8.1-py3-none-any.whl (241 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.6/241.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nInstalling collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, h5py, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow\nSuccessfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 rich-13.8.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726524595502
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the IMDB dataset (only keep top 10,000 words)\n",
        "max_features = 10000\n",
        "maxlen = 500  # Cut reviews after 500 words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess the data (pad sequences to ensure uniform input length)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(max_features, 128),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-09-16 22:09:55.247978: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-16 22:09:55.268977: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-16 22:09:55.275306: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-09-16 22:09:55.290981: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-09-16 22:09:57.122128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n2024-09-16 22:10:11.834920: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 1/5\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     31\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    888\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 889\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[1;32m    338\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph artifact\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools\u001b[38;5;241m.\u001b[39mpartial):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:121\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    125\u001b[0m     outputs,\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    127\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m )\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4060\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:906\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    910\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    911\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    912\u001b[0m   )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:987\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    985\u001b[0m   deps_control_manager \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mNullContextmanager()\n\u001b[0;32m--> 987\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default(), deps_control_manager \u001b[38;5;28;01mas\u001b[39;00m deps_ctx:\n\u001b[1;32m    988\u001b[0m   current_scope \u001b[38;5;241m=\u001b[39m variable_scope\u001b[38;5;241m.\u001b[39mget_variable_scope()\n\u001b[1;32m    989\u001b[0m   default_use_resource \u001b[38;5;241m=\u001b[39m current_scope\u001b[38;5;241m.\u001b[39muse_resource\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/framework/auto_control_deps.py:541\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    537\u001b[0m       updated_ops_which_must_run \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    538\u001b[0m           o \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mops_which_must_run\n\u001b[1;32m    539\u001b[0m           \u001b[38;5;28;01mif\u001b[39;00m o\u001b[38;5;241m.\u001b[39m_control_flow_context \u001b[38;5;129;01mis\u001b[39;00m r\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39m_control_flow_context\n\u001b[1;32m    540\u001b[0m       ]\n\u001b[0;32m--> 541\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_control_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdated_ops_which_must_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollective_manager_ids_used \u001b[38;5;241m=\u001b[39m collective_manager_scopes_used\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1726524613282
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the IMDB dataset (only keep top 10,000 words)\n",
        "max_features = 10000\n",
        "maxlen = 500  # Cut reviews after 500 words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess the data (pad sequences to ensure uniform input length)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(max_features, 128),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', 'Precision', 'recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/5\n\u001b[1m116/782\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 159ms/step - Precision: 0.5818 - accuracy: 0.5977 - loss: 0.6600 - recall: 0.8068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m117/782\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 159ms/step - Precision: 0.5824 - accuracy: 0.5983 - loss: 0.6596 - recall: 0.8062"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     31\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726524729310
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', metrics.Precision(), metrics.Recall()])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the IMDB dataset (only keep top 10,000 words)\n",
        "max_features = 10000\n",
        "maxlen = 500  # Cut reviews after 500 words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess the data (pad sequences to ensure uniform input length)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(max_features, 128),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-09-17 11:59:23.316553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-17 11:59:23.908126: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-17 11:59:24.082533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-09-17 11:59:25.406792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-09-17 11:59:28.116606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n2024-09-17 11:59:42.756405: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 203ms/step - accuracy: 0.7371 - loss: 0.5190 - precision: 0.7596 - recall: 0.6700 - val_accuracy: 0.8536 - val_loss: 0.3533 - val_precision: 0.8408 - val_recall: 0.8723\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 214ms/step - accuracy: 0.8734 - loss: 0.3085 - precision: 0.8652 - recall: 0.8866 - val_accuracy: 0.8511 - val_loss: 0.3512 - val_precision: 0.8418 - val_recall: 0.8647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 187ms/step - accuracy: 0.9134 - loss: 0.2281 - precision: 0.9126 - recall: 0.9139 - val_accuracy: 0.8756 - val_loss: 0.3103 - val_precision: 0.8726 - val_recall: 0.8797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 209ms/step - accuracy: 0.9383 - loss: 0.1681 - precision: 0.9357 - recall: 0.9406 - val_accuracy: 0.8713 - val_loss: 0.3287 - val_precision: 0.8752 - val_recall: 0.8662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 191ms/step - accuracy: 0.9563 - loss: 0.1264 - precision: 0.9581 - recall: 0.9537 - val_accuracy: 0.8547 - val_loss: 0.3853 - val_precision: 0.8609 - val_recall: 0.8460\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n782/782 - 26s - 33ms/step - accuracy: 0.8547 - loss: 0.3853 - precision: 0.8609 - recall: 0.8460\n"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Get predictions for classification metrics\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726575356381
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model and unpack all values\n",
        "results = model.evaluate(x_test, y_test, verbose=2)\n",
        "test_loss = results[0]\n",
        "test_acc = results[1]\n",
        "test_precision = results[2]\n",
        "test_recall = results[3]\n",
        "\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "print(f\"Test precision: {test_precision}\")\n",
        "print(f\"Test recall: {test_recall}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "782/782 - 27s - 34ms/step - accuracy: 0.8547 - loss: 0.3853 - precision: 0.8609 - recall: 0.8460\nTest loss: 0.3852953612804413\nTest accuracy: 0.8546800017356873\nTest precision: 0.860945999622345\nTest recall: 0.8460000157356262\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726575516764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions for classification metrics\n",
        "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")  # Convert probabilities to 0 or 1\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.86      0.86     12500\n           1       0.86      0.85      0.85     12500\n\n    accuracy                           0.85     25000\n   macro avg       0.85      0.85      0.85     25000\nweighted avg       0.85      0.85      0.85     25000\n\nConfusion Matrix:\n[[10792  1708]\n [ 1925 10575]]\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726575557865
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Multi-Class Classification"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Ensure nltk resources are available\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize the stemmer and stop words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "    # Removing special characters and numbers\n",
        "    text = re.sub(r'[^\\w\\s,.]', '', text)  # Remove punctuation, Keep periods and commas for sentence flow\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    # Tokenization\n",
        "    tokens = text.split()\n",
        "    # Removing stop words and stemming\n",
        "    tokens = [lemmatizer.stem(word) for word in tokens if word not in stop_words]\n",
        "    # Rejoin tokens into a single string\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('your_custom_dataset.csv')  # Replace with your dataset path\n",
        "texts = data['text_column'].apply(preprocess_text)  # Apply preprocessing\n",
        "labels = data['label_column']  # Replace with your label column name\n",
        "\n",
        "# One-hot encoding the labels for 3 classes (positive, negative, neutral)\n",
        "# Assuming 'label_column' contains 0 for negative, 1 for neutral, 2 for positive\n",
        "labels = to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Split the dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization and Padding\n",
        "max_features = 10000  # Number of unique words to keep\n",
        "maxlen = 500  # Maximum length of sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "x_test_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train_padded = pad_sequences(x_train_sequences, maxlen=maxlen)\n",
        "x_test_padded = pad_sequences(x_test_sequences, maxlen=maxlen)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture for Multi-class Classification\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dense(3, activation='softmax'))  # Output layer for 3 classes (positive, negative, neutral)\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss for multi-class classification\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train_padded, y_train, epochs=5, validation_data=(x_test_padded, y_test))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model and unpack the values\n",
        "results = model.evaluate(x_test_padded, y_test, verbose=2)\n",
        "test_loss = results[0]\n",
        "test_acc = results[1]\n",
        "\n",
        "# For multi-class, TensorFlow metrics like precision and recall may return macro-averaged values\n",
        "test_precision = results[2]  # Macro average precision\n",
        "test_recall = results[3]     # Macro average recall\n",
        "\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "print(f\"Test precision: {test_precision}\")\n",
        "print(f\"Test recall: {test_recall}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions for classification metrics\n",
        "y_pred_prob = model.predict(x_test_padded)  # Get probability predictions\n",
        "y_pred = y_pred_prob.argmax(axis=1)  # Convert probabilities to class labels by taking the argmax\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, cohen_kappa_score, matthews_corrcoef\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred_prob = model.predict(x_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Calculate ROC AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "\n",
        "# Calculate Cohen's Kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa: {kappa}\")\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient: {mcc}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Load the dataset\n",
        "max_features = 10000  # Top 10,000 words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Check shape of the data\n",
        "print(f\"Training data shape: {x_train.shape}, Training labels shape: {y_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}, Test labels shape: {y_test.shape}\")\n",
        "\n",
        "# View a sample of the dataset\n",
        "print(\"Sample review (as tokenized word indices):\", x_train[0])\n",
        "print(\"Corresponding label (0 = negative, 1 = positive):\", y_train[0])\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training data shape: (25000,), Training labels shape: (25000,)\nTest data shape: (25000,), Test labels shape: (25000,)\nSample review (as tokenized word indices): [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\nCorresponding label (0 = negative, 1 = positive): 1\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726448657089
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[2:5]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "array([list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n       list([1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 15305, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 64317, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 33929, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 23005, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 87564, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 18435, 192, 5, 1219, 3890, 19, 20523, 217, 4122, 1710, 537, 20341, 1236, 5, 736, 10, 10, 61, 403, 9, 47289, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 18665, 594, 7, 5168, 94, 9096, 3987, 15242, 11, 28280, 4, 538, 7, 1795, 246, 56615, 9, 10161, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 10197, 19, 49, 7, 4, 1885, 13699, 1118, 25, 80, 126, 842, 10, 10, 47289, 18223, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 16376, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 25837, 21, 29, 9, 2841, 23, 4, 1010, 26747, 793, 6, 13699, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 16376, 8, 124, 4, 882, 4, 882, 496, 27, 33029, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 11120, 1311, 8, 4, 23643, 7, 31, 7, 29851, 91, 22793, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 11876, 1775, 3353, 12716, 1846, 4, 11286, 7, 154, 5, 4, 518, 53, 13243, 11286, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 18223, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 33058, 4, 22793, 10359, 9, 242, 4, 91, 1202, 11377, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 18223, 13, 188, 1076, 3222, 19, 4, 13465, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 18223, 13, 33195, 14, 280, 13, 219, 4, 52788, 431, 758, 859, 4, 953, 1052, 12283, 7, 5991, 5, 94, 40, 25, 238, 60, 35410, 4, 15812, 804, 27767, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 22148, 23, 12, 1685, 195, 25, 238, 60, 796, 13713, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574]),\n       list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 22016, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113])],\n      dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726451690838
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset without limiting the number of words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()\n",
        "\n",
        "# Check the size of the vocabulary\n",
        "word_index = imdb.get_word_index()\n",
        "vocab_size = len(word_index)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Vocabulary size: 88584\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726451032322
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dictionary mapping word indices to actual words\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Reverse the word index to map integers back to words\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "# View a tokenized review as actual words\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_train[57]])\n",
        "\n",
        "print(\"Decoded review:\", decoded_review)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Decoded review: ? i admit i had to fast forward through this poorly transferred dvd after about 30 minutes nothing was happening and everyone has already described the plot but has anyone mentioned the opening scene a butcher knife is stabbed through a wig and it's impaled on the grass in the front yard i'm guessing the bratty kid did it put it's never explained really trippy opening br br i wish this had been a better written or thought out film because what we're left with if pretty daft and a movie that makes no sense isn't a clever movie it's just a poorly executed film br br i would like to see a cleaned up version and if there was any missing footage i would like to see if it would help otherwise this is an odd little film that is best if fast forwarded through\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726451590417
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[reverse_word_index.get(i - 3, '?') for i in x_train[2]]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "['?',\n 'this',\n 'has',\n 'to',\n 'be',\n 'one',\n 'of',\n 'the',\n 'worst',\n 'films',\n 'of',\n 'the',\n '1990s',\n 'when',\n 'my',\n 'friends',\n 'i',\n 'were',\n 'watching',\n 'this',\n 'film',\n 'being',\n 'the',\n 'target',\n 'audience',\n 'it',\n 'was',\n 'aimed',\n 'at',\n 'we',\n 'just',\n 'sat',\n 'watched',\n 'the',\n 'first',\n 'half',\n 'an',\n 'hour',\n 'with',\n 'our',\n 'jaws',\n 'touching',\n 'the',\n 'floor',\n 'at',\n 'how',\n 'bad',\n 'it',\n 'really',\n 'was',\n 'the',\n 'rest',\n 'of',\n 'the',\n 'time',\n 'everyone',\n 'else',\n 'in',\n 'the',\n 'theatre',\n 'just',\n 'started',\n 'talking',\n 'to',\n 'each',\n 'other',\n 'leaving',\n 'or',\n 'generally',\n 'crying',\n 'into',\n 'their',\n 'popcorn',\n 'that',\n 'they',\n 'actually',\n 'paid',\n 'money',\n 'they',\n 'had',\n 'earnt',\n 'working',\n 'to',\n 'watch',\n 'this',\n 'feeble',\n 'excuse',\n 'for',\n 'a',\n 'film',\n 'it',\n 'must',\n 'have',\n 'looked',\n 'like',\n 'a',\n 'great',\n 'idea',\n 'on',\n 'paper',\n 'but',\n 'on',\n 'film',\n 'it',\n 'looks',\n 'like',\n 'no',\n 'one',\n 'in',\n 'the',\n 'film',\n 'has',\n 'a',\n 'clue',\n 'what',\n 'is',\n 'going',\n 'on',\n 'crap',\n 'acting',\n 'crap',\n 'costumes',\n 'i',\n \"can't\",\n 'get',\n 'across',\n 'how',\n 'embarrasing',\n 'this',\n 'is',\n 'to',\n 'watch',\n 'save',\n 'yourself',\n 'an',\n 'hour',\n 'a',\n 'bit',\n 'of',\n 'your',\n 'life']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726451413208
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[2]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "[1,\n 14,\n 47,\n 8,\n 30,\n 31,\n 7,\n 4,\n 249,\n 108,\n 7,\n 4,\n 5974,\n 54,\n 61,\n 369,\n 13,\n 71,\n 149,\n 14,\n 22,\n 112,\n 4,\n 2401,\n 311,\n 12,\n 16,\n 3711,\n 33,\n 75,\n 43,\n 1829,\n 296,\n 4,\n 86,\n 320,\n 35,\n 534,\n 19,\n 263,\n 4821,\n 1301,\n 4,\n 1873,\n 33,\n 89,\n 78,\n 12,\n 66,\n 16,\n 4,\n 360,\n 7,\n 4,\n 58,\n 316,\n 334,\n 11,\n 4,\n 1716,\n 43,\n 645,\n 662,\n 8,\n 257,\n 85,\n 1200,\n 42,\n 1228,\n 2578,\n 83,\n 68,\n 3912,\n 15,\n 36,\n 165,\n 1539,\n 278,\n 36,\n 69,\n 44076,\n 780,\n 8,\n 106,\n 14,\n 6905,\n 1338,\n 18,\n 6,\n 22,\n 12,\n 215,\n 28,\n 610,\n 40,\n 6,\n 87,\n 326,\n 23,\n 2300,\n 21,\n 23,\n 22,\n 12,\n 272,\n 40,\n 57,\n 31,\n 11,\n 4,\n 22,\n 47,\n 6,\n 2307,\n 51,\n 9,\n 170,\n 23,\n 595,\n 116,\n 595,\n 1352,\n 13,\n 191,\n 79,\n 638,\n 89,\n 51428,\n 14,\n 9,\n 8,\n 106,\n 607,\n 624,\n 35,\n 534,\n 6,\n 227,\n 7,\n 129,\n 113]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726451329165
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the word index dictionary\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Sort the word index by the integer values (i.e., the word ranks)\n",
        "sorted_word_index = sorted(word_index.items(), key=lambda x: x[1])\n",
        "\n",
        "# Print the first 5 items\n",
        "for i in range(5):\n",
        "    print(sorted_word_index[i])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "('the', 1)\n('and', 2)\n('a', 3)\n('of', 4)\n('to', 5)\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726449323189
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check the distribution of positive/negative reviews\n",
        "print(\"Number of positive reviews:\", np.sum(y_train == 1))\n",
        "print(\"Number of negative reviews:\", np.sum(y_train == 0))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of positive reviews: 12500\nNumber of negative reviews: 12500\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726448914967
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Code Train my own model with my own dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Example dataset\n",
        "texts = [\"This is a positive review.\", \"This is a negative review.\"]\n",
        "labels = [1, 0]  # 1 for positive, 0 for negative\n",
        "\n",
        "# Parameters\n",
        "max_features = 10000  # Adjust based on your dataset\n",
        "maxlen = 500  # Adjust based on your dataset\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad sequences to ensure uniform input length\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test = data[:int(len(data) * 0.8)], data[int(len(data) * 0.8):]\n",
        "y_train, y_test = labels[:int(len(labels) * 0.8)], labels[int(len(labels) * 0.8):]\n",
        "\n",
        "# Build the LSTM model\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(max_features, 128),\n",
        "    layers.LSTM(64),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, cohen_kappa_score, matthews_corrcoef\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred_prob = model.predict(x_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Calculate ROC AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "\n",
        "# Calculate Cohen's Kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa: {kappa}\")\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient: {mcc}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Image Recognition using Convolutional Neural Networks (CNNs):\n",
        "#### This example uses TensorFlow and Keras to classify images from the CIFAR-10 dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "#x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726454093366
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[3]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/plain": "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726453454015
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[300]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "array([[[117, 123,  77],\n        [112, 120,  76],\n        [ 96, 114,  61],\n        ...,\n        [112, 121, 104],\n        [100, 110,  88],\n        [ 81, 101,  62]],\n\n       [[116, 122,  90],\n        [102, 113,  73],\n        [ 94, 113,  64],\n        ...,\n        [111, 123,  99],\n        [112, 120, 104],\n        [ 83, 102,  66]],\n\n       [[ 98, 108,  84],\n        [105, 115,  88],\n        [109, 123,  92],\n        ...,\n        [ 86, 104,  67],\n        [118, 124, 114],\n        [101, 116,  93]],\n\n       ...,\n\n       [[ 85,  98,  56],\n        [ 48,  61,  33],\n        [ 67,  86,  46],\n        ...,\n        [101, 138,  22],\n        [105, 144,  22],\n        [ 95, 121,  33]],\n\n       [[ 91, 113,  36],\n        [ 50,  66,  35],\n        [ 69,  91,  36],\n        ...,\n        [103, 135,  26],\n        [107, 141,  25],\n        [ 98, 124,  35]],\n\n       [[ 78,  97,  36],\n        [ 47,  61,  33],\n        [ 68,  90,  33],\n        ...,\n        [100, 131,  24],\n        [109, 141,  25],\n        [ 99, 122,  42]]], dtype=uint8)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 71,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726454097564
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming x_train[3][1] is the array you want to view\n",
        "image = x_train[3]\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title(\"Image from CIFAR-10 Dataset\")\n",
        "plt.axis('off')  # Hide axis\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 73,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726454114931
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Build the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}